/**
 * Main pipeline logic - orchestrates the daily job processing flow.
 * 
 * Flow:
 * 1. Run crawler to discover new jobs
 * 2. Score jobs for suitability
 * 3. Pick top N jobs
 * 4. Generate tailored summaries
 * 5. Generate PDF resumes
 * 6. Mark as "ready" for user review
 */

import { readFile } from 'fs/promises';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import { runCrawler } from '../services/crawler.js';
import { runJobSpy } from '../services/jobspy.js';
import { scoreAndRankJobs, scoreJobSuitability } from '../services/scorer.js';
import { generateSummary } from '../services/summary.js';
import { generatePdf } from '../services/pdf.js';
import * as jobsRepo from '../repositories/jobs.js';
import * as pipelineRepo from '../repositories/pipeline.js';
import { progressHelpers, resetProgress, updateProgress } from './progress.js';
import type { CreateJobInput, Job, JobSource, PipelineConfig } from '../../shared/types.js';

const __dirname = dirname(fileURLToPath(import.meta.url));
const DEFAULT_PROFILE_PATH = join(__dirname, '../../../../resume-generator/base.json');

const DEFAULT_CONFIG: PipelineConfig = {
  topN: 10,
  minSuitabilityScore: 50,
  sources: ['gradcracker', 'indeed', 'linkedin'],
  profilePath: DEFAULT_PROFILE_PATH,
  outputDir: join(__dirname, '../../../data/pdfs'),
};

// Track if pipeline is currently running
let isPipelineRunning = false;

/**
 * Run the full job discovery and processing pipeline.
 */
export async function runPipeline(config: Partial<PipelineConfig> = {}): Promise<{
  success: boolean;
  jobsDiscovered: number;
  jobsProcessed: number;
  error?: string;
}> {
  if (isPipelineRunning) {
    return {
      success: false,
      jobsDiscovered: 0,
      jobsProcessed: 0,
      error: 'Pipeline is already running',
    };
  }
  
  isPipelineRunning = true;
  resetProgress();
  const mergedConfig = { ...DEFAULT_CONFIG, ...config };
  
  // Create pipeline run record
  const pipelineRun = await pipelineRepo.createPipelineRun();
  
  console.log('üöÄ Starting job pipeline...');
  console.log(`   Config: topN=${mergedConfig.topN}, minScore=${mergedConfig.minSuitabilityScore}`);
  
  try {
    // Step 1: Load profile
    console.log('\nüìã Loading profile...');
    const profile = await loadProfile(mergedConfig.profilePath);
    
    // Step 2: Run crawler
    console.log('\nüï∑Ô∏è Running crawler...');
    progressHelpers.startCrawling();
    const existingJobUrls = await jobsRepo.getAllJobUrls();

    const discoveredJobs: CreateJobInput[] = [];
    const sourceErrors: string[] = [];

    if (mergedConfig.sources.includes('gradcracker')) {
      const crawlerResult = await runCrawler({
        existingJobUrls,
        onProgress: (update) => {
          progressHelpers.crawlingUpdate({
            listPagesProcessed: update.listPagesProcessed,
            listPagesTotal: update.listPagesTotal,
            jobCardsFound: update.jobCardsFound,
            jobPagesEnqueued: update.jobPagesEnqueued,
            jobPagesSkipped: update.jobPagesSkipped,
            jobPagesProcessed: update.jobPagesProcessed,
            phase: update.phase,
            currentUrl: update.currentUrl,
          });
        },
      });

      if (!crawlerResult.success) {
        sourceErrors.push(`gradcracker: ${crawlerResult.error ?? 'unknown error'}`);
      } else {
        discoveredJobs.push(...crawlerResult.jobs);
      }
    }

    const jobSpySites = mergedConfig.sources.filter(
      (s): s is 'indeed' | 'linkedin' => s === 'indeed' || s === 'linkedin'
    );

    if (jobSpySites.length > 0) {
      updateProgress({
        step: 'crawling',
        detail: `JobSpy: scraping ${jobSpySites.join(', ')}...`,
      });

      const jobSpyResult = await runJobSpy({ sites: jobSpySites });
      if (!jobSpyResult.success) {
        sourceErrors.push(`jobspy: ${jobSpyResult.error ?? 'unknown error'}`);
      } else {
        discoveredJobs.push(...jobSpyResult.jobs);
      }
    }

    if (discoveredJobs.length === 0 && sourceErrors.length > 0) {
      throw new Error(`All sources failed: ${sourceErrors.join('; ')}`);
    }

    if (sourceErrors.length > 0) {
      console.warn(`∆ís√ø‚Äπ,? Some sources failed: ${sourceErrors.join('; ')}`);
    }

    progressHelpers.crawlingComplete(discoveredJobs.length);
    
    // Step 3: Import discovered jobs
    console.log('\nüíæ Importing jobs to database...');
    const { created, skipped } = await jobsRepo.bulkCreateJobs(discoveredJobs);
    console.log(`   Created: ${created}, Skipped (duplicates): ${skipped}`);
    
    progressHelpers.importComplete(created, skipped);
    
    await pipelineRepo.updatePipelineRun(pipelineRun.id, {
      jobsDiscovered: created,
    });
    
    // Step 4: Get unprocessed jobs and score them
    console.log('\nüéØ Scoring jobs for suitability...');
    const unprocessedJobs = await jobsRepo.getJobsForProcessing(50);
    
    // Score jobs with progress updates
    const scoredJobs: Array<Job & { suitabilityScore: number; suitabilityReason: string }> = [];
    for (let i = 0; i < unprocessedJobs.length; i++) {
      const job = unprocessedJobs[i];
      const hasCachedScore = typeof job.suitabilityScore === 'number' && !Number.isNaN(job.suitabilityScore);
      progressHelpers.scoringJob(i + 1, unprocessedJobs.length, hasCachedScore ? `${job.title} (cached)` : job.title);

      if (hasCachedScore) {
        scoredJobs.push({
          ...job,
          suitabilityScore: job.suitabilityScore as number,
          suitabilityReason: job.suitabilityReason ?? '',
        });
        continue;
      }

      const { score, reason } = await scoreJobSuitability(job, profile);
      scoredJobs.push({
        ...job,
        suitabilityScore: score,
        suitabilityReason: reason,
      });

      // Update score in database
      await jobsRepo.updateJob(job.id, {
        suitabilityScore: score,
        suitabilityReason: reason,
      });
    }
    
    // Sort by score
    scoredJobs.sort((a, b) => b.suitabilityScore - a.suitabilityScore);
    
    // Step 5: Pick top N jobs above threshold
    const topJobs = scoredJobs
      .filter(j => j.suitabilityScore >= mergedConfig.minSuitabilityScore)
      .slice(0, mergedConfig.topN);
    
    progressHelpers.scoringComplete(scoredJobs.length, topJobs.length);
    
    console.log(`\nüìä Selected ${topJobs.length} top jobs for processing:`);
    for (const job of topJobs) {
      console.log(`   - ${job.title} @ ${job.employer} (score: ${job.suitabilityScore})`);
    }
    
    // Step 6: Process each top job
    let processed = 0;
    
    for (let i = 0; i < topJobs.length; i++) {
      const job = topJobs[i];
      console.log(`\nüìù Processing: ${job.title} @ ${job.employer}`);
      
      progressHelpers.processingJob(i + 1, topJobs.length, {
        id: job.id,
        title: job.title,
        employer: job.employer,
      });
      
      try {
        // Mark as processing
        await jobsRepo.updateJob(job.id, { status: 'processing' });
        
        // Generate tailored summary
        console.log('   Generating summary...');
        progressHelpers.generatingSummary({ title: job.title, employer: job.employer });
        
        const summaryResult = await generateSummary(
          job.jobDescription || '',
          profile
        );
        
        if (!summaryResult.success) {
          console.warn(`   ‚ö†Ô∏è Summary generation failed: ${summaryResult.error}`);
          continue;
        }
        
        // Update job with summary
        await jobsRepo.updateJob(job.id, {
          tailoredSummary: summaryResult.summary,
        });
        
        // Generate PDF
        console.log('   Generating PDF...');
        progressHelpers.generatingPdf({ title: job.title, employer: job.employer });
        
        const pdfResult = await generatePdf(
          job.id,
          summaryResult.summary!,
          mergedConfig.profilePath
        );
        
        if (!pdfResult.success) {
          console.warn(`   ‚ö†Ô∏è PDF generation failed: ${pdfResult.error}`);
          // Still mark as ready even if PDF failed - user can regenerate
        }
        
        // Mark as ready
        await jobsRepo.updateJob(job.id, {
          status: 'ready',
          pdfPath: pdfResult.pdfPath ?? undefined,
        });
        
        processed++;
        progressHelpers.jobComplete(processed, topJobs.length);
        console.log(`   ‚úÖ Ready for review!`);
        
      } catch (error) {
        console.error(`   ‚ùå Failed to process job: ${error}`);
        // Continue with next job
      }
    }
    
    // Update pipeline run as completed
    await pipelineRepo.updatePipelineRun(pipelineRun.id, {
      status: 'completed',
      completedAt: new Date().toISOString(),
      jobsProcessed: processed,
    });
    
    console.log('\nüéâ Pipeline completed!');
    console.log(`   Jobs discovered: ${created}`);
    console.log(`   Jobs processed: ${processed}`);
    
    progressHelpers.complete(created, processed);
    isPipelineRunning = false;
    
    return {
      success: true,
      jobsDiscovered: created,
      jobsProcessed: processed,
    };
    
  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error';
    
    await pipelineRepo.updatePipelineRun(pipelineRun.id, {
      status: 'failed',
      completedAt: new Date().toISOString(),
      errorMessage: message,
    });
    
    progressHelpers.failed(message);
    isPipelineRunning = false;
    
    console.error('\n‚ùå Pipeline failed:', message);
    
    return {
      success: false,
      jobsDiscovered: 0,
      jobsProcessed: 0,
      error: message,
    };
  }
}

/**
 * Process a single job (for manual processing).
 */
export async function processJob(jobId: string): Promise<{
  success: boolean;
  error?: string;
}> {
  console.log(`üìù Processing job ${jobId}...`);
  
  try {
    const job = await jobsRepo.getJobById(jobId);
    if (!job) {
      return { success: false, error: 'Job not found' };
    }
    
    const profile = await loadProfile(DEFAULT_PROFILE_PATH);
    
    // Mark as processing
    await jobsRepo.updateJob(job.id, { status: 'processing' });
    
    // Generate summary if not already done
    if (!job.tailoredSummary) {
      console.log('   Generating summary...');
      const summaryResult = await generateSummary(
        job.jobDescription || '',
        profile
      );
      
      if (summaryResult.success) {
        await jobsRepo.updateJob(job.id, {
          tailoredSummary: summaryResult.summary,
        });
        job.tailoredSummary = summaryResult.summary ?? null;
      }
    }
    
    // Generate PDF
    console.log('   Generating PDF...');
    const pdfResult = await generatePdf(
      job.id,
      job.tailoredSummary || '',
      DEFAULT_PROFILE_PATH
    );
    
    // Mark as ready
    await jobsRepo.updateJob(job.id, {
      status: 'ready',
      pdfPath: pdfResult.pdfPath ?? undefined,
    });
    
    console.log('   ‚úÖ Done!');
    return { success: true };
    
  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error';
    return { success: false, error: message };
  }
}

/**
 * Check if pipeline is currently running.
 */
export function getPipelineStatus(): { isRunning: boolean } {
  return { isRunning: isPipelineRunning };
}

/**
 * Load the user profile from JSON file.
 */
async function loadProfile(profilePath: string): Promise<Record<string, unknown>> {
  try {
    const content = await readFile(profilePath, 'utf-8');
    return JSON.parse(content);
  } catch (error) {
    console.warn('Failed to load profile, using empty object');
    return {};
  }
}
